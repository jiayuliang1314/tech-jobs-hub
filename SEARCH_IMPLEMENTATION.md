# ğŸ” æœç´¢åŠŸèƒ½å®ç°è¯¦è§£

é’ˆå¯¹**10ä¸‡èŒä½**çš„å¤šç§æœç´¢æ–¹æ¡ˆï¼Œä»æœ€ç®€å•åˆ°æœ€ä¼˜åŒ–ã€‚

---

## ğŸ“Š æœç´¢éœ€æ±‚åˆ†æ

```
æ•°æ®é‡ï¼š
- 3,000å®¶å…¬å¸
- 100,000ä¸ªèŒä½
- æ¯ä¸ªèŒä½çº¦2KBæ•°æ®

æŒ‘æˆ˜ï¼š
âŒ 100,000 Ã— 2KB = 200MBï¼ˆä¸èƒ½ä¸€æ¬¡åŠ è½½ï¼‰
âŒ ç”¨æˆ·æœç´¢è¦å¿«é€Ÿå“åº”ï¼ˆ<500msï¼‰
âŒ é›¶æˆæœ¬å®ç°
```

---

## ğŸ¯ æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | æˆæœ¬ | é€Ÿåº¦ | å¤æ‚åº¦ | æ¨èåº¦ |
|------|------|------|--------|--------|
| **æ–¹æ¡ˆ1ï¼šå‰ç«¯è¿‡æ»¤** | $0 | æ…¢ | â­ | é€‚åˆ<5000èŒä½ |
| **æ–¹æ¡ˆ2ï¼šé™æ€ç´¢å¼•** | $0 | å¿« | â­â­ | âœ… æœ€æ¨èï¼ˆé›¶æˆæœ¬ï¼‰ |
| **æ–¹æ¡ˆ3ï¼šSupabase** | $0 | å¾ˆå¿« | â­â­â­ | é€‚åˆéœ€è¦å¤æ‚æŸ¥è¯¢ |
| **æ–¹æ¡ˆ4ï¼šAlgolia** | $1/æœˆ | æœ€å¿« | â­â­â­â­ | é€‚åˆ10ä¸‡+è®¿é—® |

---

## âœ… æ–¹æ¡ˆ1ï¼šå‰ç«¯JavaScriptè¿‡æ»¤ï¼ˆDemoä¸­ä½¿ç”¨ï¼‰

### **å®ç°åŸç†ï¼š**

```javascript
// 1. åŠ è½½æ‰€æœ‰èŒä½åˆ°å†…å­˜
let allJobs = []; // å­˜å‚¨æ‰€æœ‰èŒä½

// 2. ç”¨æˆ·è¾“å…¥æ—¶å®æ—¶è¿‡æ»¤
function searchJobs() {
    const query = document.getElementById('searchInput').value.toLowerCase();
    const location = document.getElementById('locationInput').value.toLowerCase();
    
    const filtered = allJobs.filter(job => {
        const matchTitle = job.title.toLowerCase().includes(query);
        const matchCompany = job.company.toLowerCase().includes(query);
        const matchLocation = job.location.toLowerCase().includes(location);
        
        return (matchTitle || matchCompany) && matchLocation;
    });
    
    renderJobs(filtered);
}
```

### **ä¼˜ç‚¹ï¼š**
```
âœ… å®ç°ç®€å•ï¼ˆ10è¡Œä»£ç ï¼‰
âœ… æ— éœ€åç«¯
âœ… å®Œå…¨å…è´¹
âœ… å³æ—¶å“åº”
```

### **ç¼ºç‚¹ï¼š**
```
âŒ éœ€è¦åŠ è½½æ‰€æœ‰æ•°æ®ï¼ˆ100,000èŒä½ = 200MBï¼‰
âŒ é¦–æ¬¡åŠ è½½æ…¢
âŒ å ç”¨å¤§é‡å†…å­˜
âŒ ä¸é€‚åˆå¤§æ•°æ®é‡
```

### **é€‚ç”¨åœºæ™¯ï¼š**
```
âœ… èŒä½æ•°é‡ < 5,000
âœ… Demoæ¼”ç¤º
âœ… åˆæœŸæµ‹è¯•
```

---

## âœ… æ–¹æ¡ˆ2ï¼šé™æ€æœç´¢ç´¢å¼•ï¼ˆâ­æ¨èï¼Œé›¶æˆæœ¬æœ€ä¼˜ï¼‰

### **æ ¸å¿ƒæ€è·¯ï¼š**

```
å°†10ä¸‡èŒä½é¢„å¤„ç†æˆè½»é‡çº§ç´¢å¼•æ–‡ä»¶
æŒ‰éœ€åŠ è½½ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§åŠ è½½å…¨éƒ¨
```

### **æ•°æ®ç»“æ„è®¾è®¡ï¼š**

```javascript
// 1. ä¸»ç´¢å¼•æ–‡ä»¶ï¼ˆsearch-index.jsonï¼‰- åªæœ‰20MB
{
  "total": 100000,
  "jobs": [
    {
      "id": "123",
      "title": "Software Engineer",
      "company": "Airbnb", 
      "location": "SF",
      "url": "/jobs/123",
      "_k": "software engineer airbnb sf"  // æœç´¢å…³é”®è¯
    },
    // ... 100,000æ¡
  ]
}

// 2. æŒ‰é¦–å­—æ¯åˆ†ç»„ï¼ˆindex-S.jsonï¼‰- åªæœ‰2MB
// åªåŒ…å«Så¼€å¤´çš„èŒä½

// 3. æŒ‰å…¬å¸åˆ†ç»„ï¼ˆairbnb-index.jsonï¼‰
// åªåŒ…å«Airbnbçš„èŒä½
```

### **å‰ç«¯å®ç°ï¼ˆæ¸è¿›å¼åŠ è½½ï¼‰ï¼š**

```javascript
// search.js
class SmartSearch {
    constructor() {
        this.index = null;
        this.cache = new Map();
    }
    
    // æ–¹æ³•1ï¼šæ‡’åŠ è½½å®Œæ•´ç´¢å¼•
    async loadFullIndex() {
        if (this.index) return this.index;
        
        const response = await fetch('/search-index.json');
        this.index = await response.json();
        return this.index;
    }
    
    // æ–¹æ³•2ï¼šåªåŠ è½½éœ€è¦çš„éƒ¨åˆ†
    async searchByLetter(query) {
        const firstLetter = query[0].toUpperCase();
        
        // æ£€æŸ¥ç¼“å­˜
        if (this.cache.has(firstLetter)) {
            return this.filterJobs(this.cache.get(firstLetter), query);
        }
        
        // åŠ è½½è¯¥å­—æ¯çš„ç´¢å¼•
        const response = await fetch(`/index-${firstLetter}.json`);
        const jobs = await response.json();
        
        // ç¼“å­˜
        this.cache.set(firstLetter, jobs);
        
        return this.filterJobs(jobs, query);
    }
    
    // æ–¹æ³•3ï¼šæœåŠ¡ç«¯æ¸²æŸ“çš„é™æ€é¡µé¢ï¼ˆæœ€å¿«ï¼‰
    // ä¸ºçƒ­é—¨æœç´¢è¯é¢„ç”ŸæˆHTMLé¡µé¢
    // ä¾‹å¦‚ï¼š/search/software-engineer-san-francisco.html
    
    filterJobs(jobs, query) {
        const q = query.toLowerCase();
        return jobs.filter(job => 
            job._k.includes(q)  // åœ¨å…³é”®è¯å­—ç¬¦ä¸²ä¸­æœç´¢
        );
    }
}

// ä½¿ç”¨
const search = new SmartSearch();

async function handleSearch(query, location) {
    // æ™ºèƒ½å†³å®šç”¨å“ªç§æ–¹æ³•
    if (query.length > 0) {
        // æŒ‰é¦–å­—æ¯åŠ è½½
        const results = await search.searchByLetter(query);
        return results.filter(job => 
            location ? job.location.toLowerCase().includes(location.toLowerCase()) : true
        );
    } else {
        // åŠ è½½å®Œæ•´ç´¢å¼•
        const index = await search.loadFullIndex();
        return index.jobs.filter(job =>
            location ? job.location.toLowerCase().includes(location.toLowerCase()) : true
        );
    }
}
```

### **æ„å»ºç´¢å¼•è„šæœ¬ï¼š**

```python
# build_search_index.py

import json
from pathlib import Path

def build_search_index():
    """æ„å»ºè½»é‡çº§æœç´¢ç´¢å¼•"""
    data_dir = Path('data')
    output_dir = Path('web/public')
    
    full_index = []
    alpha_index = {}
    
    for company_file in data_dir.glob('*.json'):
        with open(company_file) as f:
            data = json.load(f)
        
        for job in data['jobs']:
            # ç®€åŒ–æ¡ç›®ï¼ˆå‡å°‘ä½“ç§¯ï¼‰
            entry = {
                'id': job['id'],
                't': job['title'][:50],  # ç¼©çŸ­å­—æ®µå
                'c': data['company'],
                'l': job['location'][:30],
                'u': job['url'],
                '_k': f"{job['title']} {data['company']} {job['location']}".lower()
            }
            
            full_index.append(entry)
            
            # æŒ‰é¦–å­—æ¯åˆ†ç»„
            letter = job['title'][0].upper()
            if letter not in alpha_index:
                alpha_index[letter] = []
            alpha_index[letter].append(entry)
    
    # ä¿å­˜ä¸»ç´¢å¼•ï¼ˆå‹ç¼©JSONï¼‰
    with open(output_dir / 'search-index.json', 'w') as f:
        json.dump({'jobs': full_index}, f, separators=(',', ':'))
    
    # ä¿å­˜åˆ†å­—æ¯ç´¢å¼•
    for letter, jobs in alpha_index.items():
        with open(output_dir / f'index-{letter}.json', 'w') as f:
            json.dump(jobs, f, separators=(',', ':'))
    
    print(f"âœ… Built index: {len(full_index)} jobs")

build_search_index()
```

### **æ–‡ä»¶å¤§å°ä¼˜åŒ–ï¼š**

```
ä¼˜åŒ–å‰ï¼š
100,000èŒä½ Ã— 2KB = 200MB

ä¼˜åŒ–åï¼š
100,000èŒä½ Ã— 200å­—èŠ‚ = 20MB âœ…

åˆ†ç»„åå•ä¸ªæ–‡ä»¶ï¼š
Så¼€å¤´èŒä½ Ã— 200å­—èŠ‚ = çº¦2MB âœ…

é¦–æ¬¡åŠ è½½ï¼š0MBï¼ˆæŒ‰éœ€åŠ è½½ï¼‰
æœç´¢"Software"ï¼šåªåŠ è½½2MB
æœç´¢"Airbnb"ï¼šåªåŠ è½½è¯¥å…¬å¸ç´¢å¼•
```

---

## âœ… æ–¹æ¡ˆ3ï¼šSupabaseå…¨æ–‡æœç´¢ï¼ˆæ¨èç”¨äºæ­£å¼ç½‘ç«™ï¼‰

### **ä¸ºä»€ä¹ˆç”¨Supabaseï¼Ÿ**

```
âœ… å…è´¹é¢åº¦ï¼š500MBæ•°æ®åº“
âœ… è‡ªåŠ¨RESTful API
âœ… å…¨æ–‡æœç´¢æ”¯æŒ
âœ… å®æ—¶æŸ¥è¯¢
âœ… PostgreSQLå¼ºå¤§åŠŸèƒ½

100,000èŒä½ç²¾ç®€åçº¦150MB < 500MB âœ…
```

### **æ•°æ®åº“è¡¨ç»“æ„ï¼š**

```sql
-- jobsè¡¨
CREATE TABLE jobs (
    id BIGSERIAL PRIMARY KEY,
    greenhouse_id TEXT UNIQUE,
    company TEXT,
    title TEXT,
    location TEXT,
    url TEXT,
    updated_at TIMESTAMPTZ,
    
    -- å…¨æ–‡æœç´¢å­—æ®µ
    search_vector tsvector GENERATED ALWAYS AS (
        to_tsvector('english', 
            coalesce(title, '') || ' ' || 
            coalesce(company, '') || ' ' || 
            coalesce(location, '')
        )
    ) STORED
);

-- åˆ›å»ºGINç´¢å¼•ï¼ˆåŠ é€Ÿæœç´¢ï¼‰
CREATE INDEX jobs_search_idx ON jobs USING gin(search_vector);

-- åˆ›å»ºå…¶ä»–ç´¢å¼•
CREATE INDEX jobs_company_idx ON jobs(company);
CREATE INDEX jobs_location_idx ON jobs(location);
```

### **å‰ç«¯æŸ¥è¯¢ï¼ˆè¶…å¿«ï¼‰ï¼š**

```javascript
// Supabaseå®¢æˆ·ç«¯
import { createClient } from '@supabase/supabase-js'

const supabase = createClient(
    'https://xxx.supabase.co',
    'public-anon-key'
)

// æœç´¢èŒä½
async function searchJobs(query, location, page = 1, limit = 20) {
    let queryBuilder = supabase
        .from('jobs')
        .select('*', { count: 'exact' })
    
    // å…¨æ–‡æœç´¢
    if (query) {
        queryBuilder = queryBuilder.textSearch('search_vector', query)
    }
    
    // åœ°ç‚¹è¿‡æ»¤
    if (location) {
        queryBuilder = queryBuilder.ilike('location', `%${location}%`)
    }
    
    // åˆ†é¡µ
    const start = (page - 1) * limit
    queryBuilder = queryBuilder
        .range(start, start + limit - 1)
        .order('updated_at', { ascending: false })
    
    const { data, error, count } = await queryBuilder
    
    return {
        jobs: data,
        total: count,
        page: page
    }
}

// ä½¿ç”¨ç¤ºä¾‹
const results = await searchJobs('Software Engineer', 'San Francisco');
// æŸ¥è¯¢é€Ÿåº¦ï¼š~50ms âš¡
```

### **ä¼˜ç‚¹ï¼š**

```
âœ… æŸ¥è¯¢é€Ÿåº¦æå¿«ï¼ˆ<100msï¼‰
âœ… æ”¯æŒå¤æ‚æŸ¥è¯¢ï¼ˆæ’åºã€è¿‡æ»¤ã€èšåˆï¼‰
âœ… è‡ªåŠ¨ç”ŸæˆAPI
âœ… å…è´¹500MB
âœ… å¯æ‰©å±•æ€§å¼º
```

### **ç¼ºç‚¹ï¼š**

```
âš ï¸ éœ€è¦å¯¼å…¥æ•°æ®ï¼ˆä¸€æ¬¡æ€§å·¥ä½œï¼‰
âš ï¸ è¶…è¿‡500MBéœ€è¦ä»˜è´¹ï¼ˆ$25/æœˆï¼‰
```

---

## âœ… æ–¹æ¡ˆ4ï¼šæ··åˆæ–¹æ¡ˆï¼ˆæœ€ä½³å®è·µï¼‰

### **æ ¸å¿ƒæ€è·¯ï¼š**

```
çƒ­é—¨æœç´¢ â†’ é™æ€é¢„ç”Ÿæˆé¡µé¢ï¼ˆSEOæœ€ä¼˜ï¼‰
å®æ—¶æœç´¢ â†’ å‰ç«¯è½»é‡çº§ç´¢å¼•ï¼ˆé›¶æˆæœ¬ï¼‰
å¤æ‚æŸ¥è¯¢ â†’ Supabaseï¼ˆå¯é€‰ï¼‰
```

### **å®ç°ï¼š**

```javascript
// hybrid-search.js

class HybridSearch {
    constructor() {
        this.staticPages = new Map();  // çƒ­é—¨æœç´¢è¯çš„é™æ€é¡µé¢
        this.lightIndex = null;         // è½»é‡çº§ç´¢å¼•
        this.supabase = null;           // Supabaseï¼ˆå¯é€‰ï¼‰
    }
    
    async search(query, location) {
        // ç­–ç•¥1ï¼šæ£€æŸ¥æ˜¯å¦æœ‰é¢„ç”Ÿæˆçš„é™æ€é¡µé¢
        const slug = this.toSlug(query, location);
        if (this.hasStaticPage(slug)) {
            return this.loadStaticPage(slug);
        }
        
        // ç­–ç•¥2ï¼šä½¿ç”¨å‰ç«¯è½»é‡çº§ç´¢å¼•
        if (query.length < 20) {  // çŸ­æŸ¥è¯¢ç”¨å‰ç«¯
            return this.searchInLightIndex(query, location);
        }
        
        // ç­–ç•¥3ï¼šå¤æ‚æŸ¥è¯¢ç”¨Supabaseï¼ˆå¦‚æœé…ç½®äº†ï¼‰
        if (this.supabase) {
            return this.searchInSupabase(query, location);
        }
        
        // å…œåº•ï¼šå‰ç«¯å…¨æ–‡æœç´¢
        return this.searchInLightIndex(query, location);
    }
    
    hasStaticPage(slug) {
        // æ£€æŸ¥æ˜¯å¦é¢„ç”Ÿæˆäº†è¯¥æœç´¢çš„é™æ€é¡µé¢
        // ä¾‹å¦‚ï¼š/search/software-engineer-san-francisco.html
        return this.staticPages.has(slug);
    }
    
    async searchInLightIndex(query, location) {
        // åŠ è½½è½»é‡çº§ç´¢å¼•ï¼ˆ20MBï¼‰
        if (!this.lightIndex) {
            const res = await fetch('/search-index.json');
            this.lightIndex = await res.json();
        }
        
        // å‰ç«¯è¿‡æ»¤
        const q = query.toLowerCase();
        const l = location.toLowerCase();
        
        return this.lightIndex.jobs.filter(job => 
            job._k.includes(q) && job._k.includes(l)
        );
    }
    
    toSlug(query, location) {
        return `${query}-${location}`.toLowerCase()
            .replace(/\s+/g, '-')
            .replace(/[^a-z0-9-]/g, '');
    }
}
```

### **é¢„ç”Ÿæˆçƒ­é—¨æœç´¢é¡µé¢ï¼š**

```python
# generate_popular_searches.py

POPULAR_SEARCHES = [
    ('Software Engineer', 'San Francisco'),
    ('Frontend Developer', 'Remote'),
    ('Product Manager', 'New York'),
    ('Data Scientist', 'San Francisco'),
    ('Backend Engineer', 'Remote'),
    # ... å‰100ä¸ªçƒ­é—¨æœç´¢
]

def generate_search_pages():
    """ä¸ºçƒ­é—¨æœç´¢è¯é¢„ç”ŸæˆHTMLé¡µé¢ï¼ˆSEOä¼˜åŒ–ï¼‰"""
    
    for title, location in POPULAR_SEARCHES:
        # ä»æ•°æ®ä¸­è¿‡æ»¤
        jobs = filter_jobs(title, location)
        
        # ç”ŸæˆHTML
        slug = f"{title}-{location}".lower().replace(' ', '-')
        html = generate_html(title, location, jobs)
        
        # ä¿å­˜ä¸ºé™æ€æ–‡ä»¶
        with open(f'web/public/search/{slug}.html', 'w') as f:
            f.write(html)
        
        print(f"âœ… Generated: /search/{slug}.html ({len(jobs)} jobs)")

# SEOå¥½å¤„ï¼š
# Googleä¼šç´¢å¼•è¿™100ä¸ªé¡µé¢
# ç”¨æˆ·æœç´¢"Software Engineer San Francisco"ç›´æ¥åˆ°è¾¾ä½ çš„é¡µé¢
# ä¸éœ€è¦JavaScriptï¼ŒåŠ è½½é€Ÿåº¦æå¿«
```

---

## ğŸš€ å®é™…é¡¹ç›®æ¨èæ–¹æ¡ˆï¼ˆé›¶æˆæœ¬ï¼‰

### **æ··åˆæ–¹æ¡ˆå®ç°ï¼š**

**Phase 1: å¯åŠ¨æœŸï¼ˆ0-1æœˆï¼‰**
```python
# ä½¿ç”¨æ–¹æ¡ˆ1ï¼šå‰ç«¯è¿‡æ»¤
# åªæŠ“å–500å®¶çƒ­é—¨å…¬å¸ï¼ˆçº¦15,000èŒä½ï¼‰
# æ•°æ®é‡ï¼š15,000 Ã— 2KB = 30MB
# å¯ä»¥å‰ç«¯åŠ è½½ âœ…

ä¼˜ç‚¹ï¼š
- å¿«é€Ÿä¸Šçº¿ï¼ˆ3å¤©ï¼‰
- é›¶æˆæœ¬
- éªŒè¯å¸‚åœº
```

**Phase 2: å¢é•¿æœŸï¼ˆ2-3æœˆï¼‰**
```python
# å‡çº§åˆ°æ–¹æ¡ˆ2ï¼šé™æ€ç´¢å¼•
# æŠ“å–å…¨éƒ¨3000å®¶å…¬å¸ï¼ˆ100,000èŒä½ï¼‰
# æ„å»ºè½»é‡çº§ç´¢å¼•ï¼ˆ20MBï¼‰
# æŒ‰éœ€åŠ è½½ âœ…

ä¼˜ç‚¹ï¼š
- æ”¯æŒå…¨éƒ¨æ•°æ®
- ä»ç„¶é›¶æˆæœ¬
- æœç´¢é€Ÿåº¦å¿«
```

**Phase 3: ä¼˜åŒ–æœŸï¼ˆ4-6æœˆï¼‰**
```python
# å¯é€‰å‡çº§åˆ°Supabase
# å¦‚æœæœˆæ”¶å…¥ > $1,000ï¼Œè€ƒè™‘å‡çº§

ä¼˜ç‚¹ï¼š
- æ›´å¿«çš„æŸ¥è¯¢
- å¤æ‚ç­›é€‰
- æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ

æˆæœ¬ï¼š$0ï¼ˆå…è´¹ç‰ˆï¼‰æˆ– $25/æœˆ
```

---

## ğŸ’» å®Œæ•´ä»£ç ç¤ºä¾‹

### **HTMLç‰ˆæœç´¢å®ç°ï¼ˆå½“å‰Demoï¼‰**

```html
<!-- search.html -->
<script>
let allJobs = [];

// åŠ è½½æ‰€æœ‰èŒä½
async function loadJobs() {
    // æ–¹å¼1ï¼šä»GitHubåŠ è½½
    const companies = ['airbnb', 'stripe', 'notion']; // ä½ çš„3000å®¶
    
    for (const company of companies) {
        try {
            const res = await fetch(`https://raw.githubusercontent.com/YOUR_USERNAME/greenhouse-jobs/main/data/${company}.json`);
            const data = await res.json();
            allJobs = allJobs.concat(data.jobs.map(j => ({
                ...j,
                company: company
            })));
        } catch (e) {
            console.error(`Failed to load ${company}:`, e);
        }
    }
    
    console.log(`Loaded ${allJobs.length} jobs`);
}

// æœç´¢å‡½æ•°
function searchJobs() {
    const query = document.getElementById('searchInput').value.toLowerCase();
    const location = document.getElementById('locationInput').value.toLowerCase();
    
    const results = allJobs.filter(job => {
        // æ ‡é¢˜æˆ–å…¬å¸ååŒ¹é…
        const matchQuery = !query || 
            job.title.toLowerCase().includes(query) ||
            job.company.toLowerCase().includes(query);
        
        // åœ°ç‚¹åŒ¹é…
        const matchLocation = !location ||
            job.location.toLowerCase().includes(location);
        
        return matchQuery && matchLocation;
    });
    
    // æ’åºï¼šæœ€è¿‘æ›´æ–°çš„ä¼˜å…ˆ
    results.sort((a, b) => 
        new Date(b.updated_at) - new Date(a.updated_at)
    );
    
    // æ˜¾ç¤ºç»“æœ
    displayResults(results);
}

function displayResults(jobs) {
    const container = document.getElementById('results');
    container.innerHTML = jobs.map(job => `
        <div class="job-card">
            <h3>${job.title}</h3>
            <p>${job.company} â€¢ ${job.location}</p>
            <a href="/jobs/${job.id}">View Details</a>
        </div>
    `).join('');
}

// é¡µé¢åŠ è½½æ—¶åŠ è½½æ•°æ®
loadJobs();
</script>
```

### **Next.jsç‰ˆæœç´¢å®ç°ï¼ˆæ›´ä¼˜ï¼‰**

```typescript
// pages/api/search.ts - æœåŠ¡ç«¯API

import type { NextApiRequest, NextApiResponse } from 'next'
import fs from 'fs'
import path from 'path'

export default async function handler(
  req: NextApiRequest,
  res: NextApiResponse
) {
    const { q, location, page = 1, limit = 20 } = req.query
    
    try {
        // åŠ è½½æœç´¢ç´¢å¼•
        const indexPath = path.join(process.cwd(), 'public', 'search-index.json')
        const index = JSON.parse(fs.readFileSync(indexPath, 'utf-8'))
        
        // è¿‡æ»¤
        let results = index.jobs
        
        if (q) {
            const query = (q as string).toLowerCase()
            results = results.filter((job: any) => 
                job._k.includes(query)
            )
        }
        
        if (location) {
            const loc = (location as string).toLowerCase()
            results = results.filter((job: any) =>
                job.l.toLowerCase().includes(loc)
            )
        }
        
        // åˆ†é¡µ
        const start = (Number(page) - 1) * Number(limit)
        const end = start + Number(limit)
        const paged = results.slice(start, end)
        
        res.status(200).json({
            total: results.length,
            page: Number(page),
            limit: Number(limit),
            jobs: paged
        })
        
    } catch (error) {
        res.status(500).json({ error: 'Search failed' })
    }
}
```

```typescript
// pages/jobs/index.tsx - å‰ç«¯è°ƒç”¨

async function searchJobs(query: string, location: string) {
    const res = await fetch(
        `/api/search?q=${encodeURIComponent(query)}&location=${encodeURIComponent(location)}`
    )
    const data = await res.json()
    setJobs(data.jobs)
    setTotal(data.total)
}
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### **æœç´¢é€Ÿåº¦æµ‹è¯•ï¼ˆ10ä¸‡èŒä½ï¼‰**

| æ–¹æ¡ˆ | é¦–æ¬¡åŠ è½½ | æœç´¢å»¶è¿Ÿ | ç”¨æˆ·ä½“éªŒ |
|------|----------|----------|----------|
| å‰ç«¯å…¨é‡åŠ è½½ | 30ç§’ âŒ | 10ms | å·® |
| å‰ç«¯è½»é‡ç´¢å¼• | 2ç§’ âœ… | 50ms | å¥½ |
| Supabase | 0ç§’ âœ… | 80ms | å¾ˆå¥½ |
| é™æ€é¢„ç”Ÿæˆ | 0ç§’ âœ… | 0ms âš¡ | æœ€å¥½ |

---

## ğŸ¯ æˆ‘çš„æ¨èï¼ˆé›¶æˆæœ¬æ–¹æ¡ˆï¼‰

### **ç¬¬ä¸€é˜¶æ®µï¼šå‰ç«¯è½»é‡ç´¢å¼•**

```
1. æ„å»ºæœç´¢ç´¢å¼•ï¼ˆè¿è¡Œ1æ¬¡ï¼‰
   python3 build_search_index.py

2. ç”Ÿæˆæ–‡ä»¶ï¼š
   - search-index.json (20MB)
   - index-A.json, index-B.json... (å„2MB)

3. å‰ç«¯æŒ‰éœ€åŠ è½½
   - ç”¨æˆ·æœç´¢"Software" â†’ åªåŠ è½½index-S.json
   - æœç´¢é€Ÿåº¦ï¼š<200ms
   - ç”¨æˆ·ä½“éªŒï¼šè‰¯å¥½ âœ…

æˆæœ¬ï¼š$0
é€‚åˆï¼š0-10ä¸‡è®¿é—®/æœˆ
```

### **ç¬¬äºŒé˜¶æ®µï¼ˆå¯é€‰ï¼‰ï¼šå‡çº§Supabase**

```
å½“æœˆæ”¶å…¥ > $1,000æ—¶è€ƒè™‘

ä¼˜åŠ¿ï¼š
- æŸ¥è¯¢é€Ÿåº¦ <100ms
- æ”¯æŒå¤æ‚ç­›é€‰
- æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ

æˆæœ¬ï¼š$0ï¼ˆå…è´¹ç‰ˆå¤Ÿç”¨ï¼‰
é€‚åˆï¼š10ä¸‡+ è®¿é—®/æœˆ
```

---

## ğŸ”§ ç«‹å³å®ç°

### **åˆ›å»ºbuild_search_index.pyï¼š**

æˆ‘å¯ä»¥å¸®ä½ ç”Ÿæˆè¿™ä¸ªè„šæœ¬ï¼Œè¿è¡Œä¸€æ¬¡å°±èƒ½æ„å»ºå®Œæ•´çš„æœç´¢ç´¢å¼•ã€‚

### **ä¿®æ”¹å‰ç«¯é›†æˆæœç´¢ï¼š**

æŠŠæœç´¢ç´¢å¼•é›†æˆåˆ°HTML demoæˆ–Next.jsç½‘ç«™ã€‚

---

## ğŸ“ å‘Šè¯‰æˆ‘

1. ä½ æƒ³ç”¨å“ªä¸ªæ–¹æ¡ˆï¼Ÿ
   - å‰ç«¯è½»é‡ç´¢å¼•ï¼ˆé›¶æˆæœ¬ï¼Œæ¨èï¼‰
   - Supabaseï¼ˆæ›´å¿«ï¼Œä¹Ÿå…è´¹ï¼‰
   - æ··åˆæ–¹æ¡ˆ

2. æˆ‘å¸®ä½ å®ç°æœç´¢ç´¢å¼•æ„å»ºè„šæœ¬ï¼Ÿ

3. è¿˜æ˜¯å…ˆçœ‹çœ‹å½“å‰Demoçš„ç®€å•æœç´¢æ•ˆæœï¼Ÿ

**ç°åœ¨Demoä¸­çš„æœç´¢æ˜¯æœ€ç®€å•çš„å‰ç«¯è¿‡æ»¤ï¼ˆé€‚åˆæ¼”ç¤ºï¼‰ï¼Œå®é™…é¡¹ç›®éœ€è¦ä¼˜åŒ–ï¼**
