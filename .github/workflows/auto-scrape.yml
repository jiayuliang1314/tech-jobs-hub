name: Auto Scrape Jobs

on:
  schedule:
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      batch:
        description: 'Batch number (0=1-1000, 1=1001-2000, 2=2001-2754)'
        required: false
        default: 'auto'
      max_companies:
        description: 'Max companies to scrape (0=all)'
        required: false
        default: '50'

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Scrape jobs
        run: |
          echo "Starting scrape..."
          
          # 计算批次
          if [ "${{ github.event.inputs.batch }}" = "auto" ] || [ -z "${{ github.event.inputs.batch }}" ]; then
            # 自动模式：每天1000家，3天循环
            DAY=$(date +%j)
            BATCH=$((DAY % 3))
          else
            # 手动指定批次
            BATCH=${{ github.event.inputs.batch }}
          fi
          
          START=$((BATCH * 1000 + 1))
          END=$((START + 999))
          
          echo "Batch $BATCH: companies $START-$END"
          
          # 提取公司列表
          sed -n "${START},${END}p" companies_tokens_only.txt > batch.txt
          
          # 限制抓取数量（手动触发时）
          MAX_COMPANIES=${{ github.event.inputs.max_companies }}
          if [ ! -z "$MAX_COMPANIES" ] && [ "$MAX_COMPANIES" != "0" ]; then
            head -n $MAX_COMPANIES batch.txt > batch_limited.txt
            mv batch_limited.txt batch.txt
            echo "Limited to first $MAX_COMPANIES companies"
          fi
          
          wc -l batch.txt
          
          # 抓取（不获取详情，使用懒加载）
          python3 fetch_greenhouse_jobs.py --companies batch.txt --output data --delay 1.5
      
      - name: Build index
        run: |
          python3 build_search_index.py --data data --output .
      
      - name: Create stats
        run: |
          python3 -c 'import json; from pathlib import Path; jobs=0; companies=0
          for f in Path("data").glob("*.json"):
              if not f.name.startswith("_"):
                  try:
                      d=json.load(open(f)); jobs+=d.get("job_count",0); companies+=1
                  except: pass
          json.dump({"jobs":jobs,"companies":companies,"updated":"'$(date -u +%Y-%m-%d)'"}, open("stats.json","w"))'
      
      - name: Commit
        run: |
          git config user.name "Bot"
          git config user.email "bot@github.com"
          git add data/ *.json indexes/ || true
          if git diff --staged --quiet; then
            echo "✅ No changes detected"
          else
            git commit -m "Update jobs data $(date +%Y-%m-%d)"
            git push
            echo "✅ Changes committed and pushed"
          fi
